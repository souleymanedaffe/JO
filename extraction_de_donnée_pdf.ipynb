{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traitement du fichier : C:\\Users\\daffes\\Desktop\\projet_datathom\\22. Autorisation d'utilisation et d'exploitation de l'image d'un salarié du groupe AREP màj 2024.pdf\n",
      "Traitement du fichier : C:\\Users\\daffes\\Desktop\\projet_datathom\\8. Bulletin dispense d'affiliation de droit.pdf\n",
      "\n",
      "✅ Terminé ! Résultats enregistrés dans C:\\Users\\daffes\\Desktop\\projet_datathom\\PDF\\Resulta\\missions_classees_openai.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "import time\n",
    "import pdfplumber\n",
    "import pytesseract\n",
    "import openai\n",
    "from PIL import Image\n",
    "\n",
    "# Mettez ici votre clé d'API OpenAI\n",
    "openai.api_key =\"\"\n",
    "def pdf_has_text(pdf_path: str) -> bool:\n",
    "    \"\"\"\n",
    "    Vérifie si un PDF contient une couche texte ou s'il s'agit d'un scan.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            if len(pdf.pages) == 0:\n",
    "                return False\n",
    "            text = pdf.pages[0].extract_text()\n",
    "            return bool(text and len(text.strip()) > 10)\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def extract_text_from_pdf(pdf_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Extrait le texte d'un PDF contenant une couche texte.\n",
    "    \"\"\"\n",
    "    all_text = []\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            txt = page.extract_text()\n",
    "            if txt:\n",
    "                all_text.append(txt)\n",
    "    return \"\\n\".join(all_text)\n",
    "\n",
    "def ocr_pdf(pdf_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Effectue l'OCR sur un PDF scanné et retourne le texte extrait.\n",
    "    \"\"\"\n",
    "    text_parts = []\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            image = page.to_image(resolution=300)\n",
    "            pil_img = image.original\n",
    "            page_text = pytesseract.image_to_string(pil_img, lang=\"fra\")  # OCR en français\n",
    "            if page_text.strip():\n",
    "                text_parts.append(page_text)\n",
    "    return \"\\n\".join(text_parts)\n",
    "\n",
    "def chunk_text(text, chunk_size=2000):\n",
    "    \"\"\"\n",
    "    Découpe un texte en morceaux de taille maximale 'chunk_size'.\n",
    "    \"\"\"\n",
    "    return [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "\n",
    "def analyze_statuts_chunk(chunk_text: str, model=\"gpt-4\"):\n",
    "    \"\"\"\n",
    "    Analyse un chunk de texte avec OpenAI. Gère les erreurs de rate limit.\n",
    "    \"\"\"\n",
    "    system_msg = (\n",
    "        \"Tu es un assistant qui analyse les statuts d'une entreprise. \"\n",
    "        \"Tu dois extraire les informations suivantes et retourner un JSON strict :\\n\\n\"\n",
    "        \"1) enterprise_name : nom de l'entreprise s'il est indiqué clairement dans les statuts.\\n\"\n",
    "        \"2) raison_d_etre : si elle est définie, sinon laisse vide.\\n\"\n",
    "        \"3) objectifs_sociaux : si mentionnés, sinon vide.\\n\"\n",
    "        \"4) objectifs_environnementaux : si mentionnés, sinon vide.\\n\"\n",
    "        \"5) mission_nature : choisis parmi 'RSE', 'transformative de l’entreprise', \"\n",
    "        \"'transformative du secteur d’activité', ou 'Aucune'.\\n\\n\"\n",
    "        \"Ne réponds pas avec du texte supplémentaire, uniquement un objet JSON valide, comme ceci :\\n\"\n",
    "        \"{\\n\"\n",
    "        '  \"enterprise_name\": \"...\",\\n'\n",
    "        '  \"raison_d_etre\": \"...\",\\n'\n",
    "        '  \"objectifs_sociaux\": \"...\",\\n'\n",
    "        '  \"objectifs_environnementaux\": \"...\",\\n'\n",
    "        '  \"mission_nature\": \"...\" \\n'\n",
    "        \"}\\n\"\n",
    "    )\n",
    "\n",
    "    user_msg = f\"Voici le texte intégral (ou partiel) des statuts :\\n\\n{chunk_text}\\n\\nAnalyse et retourne le JSON demandé.\"\n",
    "\n",
    "    attempt = 0\n",
    "    while attempt < 5:  # Réessayer jusqu'à 5 fois en cas d'erreur de Rate Limit\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=model,\n",
    "                temperature=0.1,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_msg},\n",
    "                    {\"role\": \"user\", \"content\": user_msg},\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            content = response.choices[0].message[\"content\"].strip()\n",
    "            if not content:\n",
    "                print(\"⚠️ Réponse OpenAI vide !\")\n",
    "                return {}\n",
    "\n",
    "            return json.loads(content)\n",
    "\n",
    "        except openai.error.RateLimitError as e:\n",
    "            wait_time = 10 * (attempt + 1)  # Attente progressive (10s, 20s, 30s...)\n",
    "            print(f\"⚠️ Rate Limit atteint, attente de {wait_time} secondes...\")\n",
    "            time.sleep(wait_time)\n",
    "            attempt += 1\n",
    "\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"⚠️ Erreur JSON : Réponse mal formatée\")\n",
    "            return {}\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"⚠️ Erreur OpenAI :\", e)\n",
    "            return {}\n",
    "\n",
    "    print(\"❌ Échec après plusieurs tentatives\")\n",
    "    return {}\n",
    "\n",
    "def analyze_statuts_openai(full_text: str, model=\"gpt-4\"):\n",
    "    \"\"\"\n",
    "    Gère le cas où 'full_text' dépasse la limite de tokens en segmentant (chunking) si nécessaire.\n",
    "    \"\"\"\n",
    "    MAX_CHARS = 12000  # Seuil pour découper en chunks\n",
    "\n",
    "    if len(full_text) > MAX_CHARS:\n",
    "        print(f\"Texte trop volumineux ({len(full_text)} caractères). Découpage en chunks...\")\n",
    "        text_chunks = chunk_text(full_text, chunk_size=2000)\n",
    "\n",
    "        aggregated_result = {\n",
    "            \"enterprise_name\": \"\",\n",
    "            \"raison_d_etre\": \"\",\n",
    "            \"objectifs_sociaux\": \"\",\n",
    "            \"objectifs_environnementaux\": \"\",\n",
    "            \"mission_nature\": \"\"\n",
    "        }\n",
    "\n",
    "        for idx, ch in enumerate(text_chunks):\n",
    "            print(f\"Analyse du chunk {idx+1}/{len(text_chunks)}...\")\n",
    "            partial_result = analyze_statuts_chunk(ch, model)\n",
    "\n",
    "            for key in aggregated_result:\n",
    "                if not aggregated_result[key] and partial_result.get(key):\n",
    "                    aggregated_result[key] = partial_result[key]\n",
    "\n",
    "        return aggregated_result\n",
    "    else:\n",
    "        return analyze_statuts_chunk(full_text, model)\n",
    "\n",
    "def process_pdfs_in_folder(pdf_folder: str, output_csv: str, model=\"gpt-4\"):\n",
    "    \"\"\"\n",
    "    Parcourt chaque PDF d'un dossier, extrait (ou OCR si nécessaire) le texte,\n",
    "    l'analyse via OpenAI et enregistre dans un CSV.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    pdf_files = [f for f in os.listdir(pdf_folder) if f.lower().endswith(\".pdf\")]\n",
    "\n",
    "    for fname in pdf_files:\n",
    "        pdf_path = os.path.join(pdf_folder, fname)\n",
    "        print(f\"Traitement du fichier : {pdf_path}\")\n",
    "\n",
    "        if pdf_has_text(pdf_path):\n",
    "            text = extract_text_from_pdf(pdf_path)\n",
    "        else:\n",
    "            text = ocr_pdf(pdf_path)\n",
    "\n",
    "        analysis = analyze_statuts_openai(text, model)\n",
    "\n",
    "        row = {\n",
    "            \"fichier\": fname,\n",
    "            \"enterprise_name\": analysis.get(\"enterprise_name\", \"\"),\n",
    "            \"raison_d_etre\": analysis.get(\"raison_d_etre\", \"\"),\n",
    "            \"objectifs_sociaux\": analysis.get(\"objectifs_sociaux\", \"\"),\n",
    "            \"objectifs_environnementaux\": analysis.get(\"objectifs_environnementaux\", \"\"),\n",
    "            \"mission_nature\": analysis.get(\"mission_nature\", \"\")\n",
    "        }\n",
    "        results.append(row)\n",
    "\n",
    "    with open(output_csv, mode=\"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "        fieldnames = [\n",
    "            \"fichier\",\n",
    "            \"enterprise_name\",\n",
    "            \"raison_d_etre\",\n",
    "            \"objectifs_sociaux\",\n",
    "            \"objectifs_environnementaux\",\n",
    "            \"mission_nature\"\n",
    "        ]\n",
    "        \n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for r in results:\n",
    "            writer.writerow(r)\n",
    "\n",
    "    print(f\"\\n✅ Terminé ! Résultats enregistrés dans {output_csv}\")\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    DOSSIER_PDF = r\"C:\\Users\\daffes\\Desktop\\projet_datathom\"\n",
    "\n",
    "    FICHIER_SORTIE = r\"C:\\Users\\daffes\\Desktop\\projet_datathom\\PDF\\Resulta\\missions_classees_openai.csv\"\n",
    "    \n",
    "    # Utilisation de gpt-3.5-turbo pour économiser des tokens (optionnel)\n",
    "    process_pdfs_in_folder(DOSSIER_PDF, FICHIER_SORTIE, model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
